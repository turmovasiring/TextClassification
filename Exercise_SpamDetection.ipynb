{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise-SpamDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/TextClassification/blob/master/Exercise_SpamDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPkfUyg1EXpD",
        "colab_type": "text"
      },
      "source": [
        "# Comparing several classifiers for spam detection\n",
        "\n",
        "The goal of this exercise is to compare different classifiers for the taks of spam detection. Some possible classifiers are:\n",
        "\n",
        "1. Logistic Regression\n",
        "2. Linear Support Vector Machine\n",
        "3. Random Forest\n",
        "4. Multi-layer Perceptron classifier.\n",
        "5. k-Nearest Neighbors classifier\n",
        "6. Naïve Bayes. \n",
        "\n",
        "You will have to train an test these models using the spam detection dataset. \n",
        "Compare their results and propose the best classifier. \n",
        "\n",
        "\n",
        "Dataset:  https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRNgZ2MTEXpR",
        "colab_type": "text"
      },
      "source": [
        "## Loading data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM0jAoJ4E6qX",
        "colab_type": "code",
        "outputId": "23dceb4c-f8de-4fd9-9a8b-ec2224ef6f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "sst_home='drive/My Drive/Colab Notebooks/'\n",
        "#modify this path \n",
        "path=sst_home+'TESI/3-TextClasification/data/SMSSpamCollection'\n",
        "\n",
        "import pandas\n",
        "import csv\n",
        "\n",
        "messages = pandas.read_csv(path, sep='\\t', quoting=csv.QUOTE_NONE, names=[\"label\", \"message\"])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToPbdgdvEXpZ",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning texts\n",
        "The following cell contains the code to clean the texts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUCZiIEgEXpb",
        "colab_type": "code",
        "outputId": "c2d649f5-517e-48fd-df1c-eb04edadddaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "\n",
        "def cleanText(text):\n",
        "    text=str(text).lower()\n",
        "    #tokeniza the text\n",
        "    tokens=word_tokenize(text)\n",
        "    #remove the stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords_en]\n",
        "    #(4) obtain the stems\n",
        "    tokens = [PorterStemmer().stem(word) for word in tokens]\n",
        "    #(5) finally, remove words with len <3 and words that contain numbers, puntuaction, ect\n",
        "    min_length = 3\n",
        "    p = re.compile('[a-zA-Z]+');\n",
        "    filtered_tokens=[]\n",
        "    for token in tokens:\n",
        "        if len(token)>=min_length and p.match(token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXmBtrQ-EXqL",
        "colab_type": "text"
      },
      "source": [
        "## Split the dataset: training and test datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b-Ely32EXqM",
        "colab_type": "code",
        "outputId": "a7837a66-eb82-4ef4-b07b-13813b5d8eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split \n",
        "\n",
        "msg_train, msg_test, label_train, label_test = train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
        "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4459 1115 5574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbtlMzXVEXqS",
        "colab_type": "text"
      },
      "source": [
        "## Using TF-IDF model to represent texts \n",
        "Now, we are going to train a tf-idf model using the training dataset. Then, we will apply this tf-idf model to tranform the training and test sets. Remember that first you need to obtain the bow model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3TLq97pEXqU",
        "colab_type": "code",
        "outputId": "0e1856ef-b966-41c2-a68a-8cb814a75816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "bow = CountVectorizer(analyzer=cleanText).fit(msg_train)\n",
        "#transform the training set to bow model\n",
        "bow_train = bow.transform(msg_train)\n",
        "#transform the test set to bow model\n",
        "bow_test=bow.transform(msg_test)\n",
        "\n",
        "\n",
        "#learn the tf-idf model from the training bow\n",
        "tfidf_transformer = TfidfTransformer().fit(bow_train)\n",
        "#transform the training set to tf-idf model\n",
        "tfidf_train = tfidf_transformer.transform(bow_train)\n",
        "#transform the test set to tf-idf model\n",
        "tfidf_test = tfidf_transformer.transform(bow_test)\n",
        "\n",
        "print('matrices obtained')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrices obtained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5F0VuYVEXqY",
        "colab_type": "text"
      },
      "source": [
        "## Training and test a classifier\n",
        "\n",
        "The following cell shows you how to train and test a classifier. In particular, we use the **MultinomialNB** class, which implements the **Naive Bayes** classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shHyYDEFEXqZ",
        "colab_type": "code",
        "outputId": "18fba638-9a2f-4365-98ec-9c3009bc5a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=cleanText)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
        "])\n",
        "\n",
        "pipeline.fit(msg_train,label_train)\n",
        "predictions = pipeline.predict(msg_test)\n",
        "\n",
        "print( classification_report(label_test, predictions))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98       961\n",
            "        spam       0.97      0.75      0.85       154\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.97      0.88      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiW4gpfran28",
        "colab_type": "text"
      },
      "source": [
        "Now, you should add the code to train the models using other classifiers. Compare their results and choose the best. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sza6h9e1rQqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}